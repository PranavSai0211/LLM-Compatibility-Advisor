## Direct Link for the app##
# https://huggingface.co/spaces/qwerty45-uiop/LLM-Compatibilty-Advisor #

# ğŸ§  Enhanced LLM Compatibility Advisor

A powerful Streamlit application for recommending the best open-source large language models (LLMs) based on device specifications. Designed for students, researchers, and developers looking to run LLMs on laptops or mobile devices with limited or varying RAM/GPU capabilities.

---

## ğŸš€ Features

- ğŸ” **Personalized LLM Recommendations** based on device RAM
- ğŸ§  **150+ Popular Open Source Models** across categories (general, code, chat, reasoning, multimodal)
- ğŸ“‰ **Quantization Support** (FP16, 8-bit, 4-bit, 2-bit) with download size estimations
- âš™ï¸ **Inference Speed & VRAM Estimator**
- ğŸ“± **Mobile & Laptop Analysis Support**
- ğŸ“Š **Batch Insights** for analyzing multiple student entries
- ğŸ“ˆ **RAM Distribution Visualizations**
- ğŸ” **Model Comparison Tool**
- âœ… **Offline/Demo Mode** when Excel files are missing
- ğŸ’¾ **GPU Recommendations** using a built-in compatibility database

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ streamlit_app.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ BITS_INTERNS.xlsx
â”‚   â””â”€â”€ Summer of AI - ICFAI  (Responses) (3).xlsx
```

- `streamlit_app.py` â€“ Main Streamlit app file
- `src/` â€“ Directory containing Excel response data

---
``


## â–¶ï¸ Running the App

```bash
streamlit run streamlit_app.py
```

Make sure Excel files are placed in the `src/` folder.

---


## ğŸ“Š RAM-based Model Categories

| Tier         | RAM Range | Description                       |
|--------------|-----------|------------------------------------|
| Ultra Low    | â‰¤ 2GB     | Tiny models for basic tasks        |
| Low          | 3â€“4GB     | Entry-level LLMs                   |
| Moderate Low | 5â€“6GB     | Standard 7B models (quantized)     |
| Moderate     | 7â€“8GB     | Chat/code-focused, 7B-class        |
| Good         | 9â€“16GB    | Advanced 13B-class models          |
| High         | 17â€“32GB   | Large 30Bâ€“70B quantized models     |
| Ultra High   | >32GB     | Full-size 70B+ models (FP16)       |

## ğŸ“š Credits

- Developed with â¤ï¸ using [Streamlit](https://streamlit.io), [Hugging Face](https://huggingface.co), and [Plotly](https://plotly.com)
- Data format based on internship responses from BITS & ICFAI students.

---

## ğŸ“ License

This project is open source and available under the [MIT License](LICENSE).
